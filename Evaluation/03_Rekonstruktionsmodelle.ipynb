{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekonstruktionsmodelle\n",
    "\n",
    "## Motivation\n",
    "Ziel der Arbeit ist eine Evaluation der domänenspezifischen Einsatzfähigkeit des RAVE-Modells zur Aufbereitung und Rekonstruktion von Audiodateien. Die denkbaren Anwendungen sind vielseitig. Die Reduktion auf und die anschließende Rekonstruktion aus einem latenten Raum prädestiniert Autoencoder-Architekturen dazu, in Kompressionsverfahren eingesetzt zu werden, um die Kosten für Datenspeicherung und -Übertragung zu reduzieren. Darüber hinaus sind Szenarien denen Fehlerbehaftete Signale mithilfe von Autoencodern verbessert werden können. Variational Autoencoder können sich in solchen Situationen als besonders nützlich erweisen, da sie sich aufgrund der zusätzlichen Anforderungen an den latenten Raum grundsätzlich besser für Manipulationen der latenten Vektoren eignen. \n",
    "\n",
    "Die Einsatzfähigkeit des RAVE-VAEs soll im Folgenden \n",
    "\n",
    "## Arten der Signalverfremdung\n",
    "1. Keine Signalverfremdung\n",
    "2. Virtuelle Bit-Reduktion auf eine Tiefe von 12 Bits\n",
    "3. kurze Aussetzer\n",
    "4. lange Aussetzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleiche Latent Space von unverzerrten Testdaten mit Latent Space von verzerrten \n",
    "# Testdaten, um zu verstehen, ob ein Zusammenhang besteht, der für eine Latent Space \n",
    "# basierte Verbesserung genutzt werden kann.\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "# Load model\n",
    "MODEL_PATH = pathlib.Path(\"../../runs/rave_scapes_3/rave_scapes_3.ts\")\n",
    "torch.set_grad_enabled(False)\n",
    "model = torch.jit.load(MODEL_PATH).eval().double()\n",
    "\n",
    "originals = pathlib.Path(\"../../data/soundscapes_multiloc_corr/pollutions/001/test_audio\")\n",
    "bit_reduced = pathlib.Path(\"../../data/soundscapes_multiloc_corr/pollutions/002/test_audio\")\n",
    "down_sampled = pathlib.Path(\"../../data/soundscapes_multiloc_corr/pollutions/003/test_audio\")\n",
    "\n",
    "# Sample 10 random data points for rough estimation\n",
    "random.seed(0)\n",
    "samples = list(originals.glob(\"*.wav\"))\n",
    "random.shuffle(samples)\n",
    "samples = samples[:10]\n",
    "\n",
    "# Get the latent spaces from originals\n",
    "ls_orig = []\n",
    "for f in samples:\n",
    "    x, sr = sf.read(f)\n",
    "    z = model.encode(torch.from_numpy(x).reshape(1, 1, -1).double())\n",
    "    ls_orig.append(z)\n",
    "\n",
    "# Get latent spaces from bit reduced\n",
    "ls_bitr = []\n",
    "for f in samples:\n",
    "    x, sr = sf.read(bit_reduced / f.name)\n",
    "    z = model.encode(torch.from_numpy(x).reshape(1, 1, -1).double())\n",
    "    ls_bitr.append(z)\n",
    "    \n",
    "# Get latent spaces from down sampled\n",
    "ls_down = []\n",
    "for f in samples:\n",
    "    x, sr = sf.read(down_sampled / f.name)\n",
    "    z = model.encode(torch.from_numpy(x).reshape(1, 1, -1).double())\n",
    "    ls_down.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "create_latent_space_matrix = lambda x: torch.concat([elem[0].t() for elem in x])\n",
    "px.bar(create_latent_space_matrix(ls_bitr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
